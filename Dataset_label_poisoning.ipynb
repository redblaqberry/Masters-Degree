{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7605643,"sourceType":"datasetVersion","datasetId":4428041}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data label poisoning","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nimport json\nimport requests\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f'Using {device} for inference')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:22:31.771839Z","iopub.execute_input":"2024-03-03T11:22:31.772208Z","iopub.status.idle":"2024-03-03T11:22:31.780526Z","shell.execute_reply.started":"2024-03-03T11:22:31.772179Z","shell.execute_reply":"2024-03-03T11:22:31.779637Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Using cuda for inference\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchviz\n!pip install torchsummary\n!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:06:51.224124Z","iopub.execute_input":"2024-03-03T11:06:51.224969Z","iopub.status.idle":"2024-03-03T11:07:34.153023Z","shell.execute_reply.started":"2024-03-03T11:06:51.224934Z","shell.execute_reply":"2024-03-03T11:07:34.152092Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torchviz\n  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchviz) (2.1.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from torchviz) (0.20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchviz) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchviz) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchviz) (1.3.0)\nBuilding wheels for collected packages: torchviz\n  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=6530fb0704c495771cb20d633fee3f8440717d90a2a80536229c48b6bd096329\n  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\nSuccessfully built torchviz\nInstalling collected packages: torchviz\nSuccessfully installed torchviz-0.0.2\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet_pytorch\n  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=b29d4d734d7bc143ffc344e5b2916eab40e1449022772eb4a1059f490127ddc8\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet_pytorch\nInstalling collected packages: efficientnet_pytorch\nSuccessfully installed efficientnet_pytorch-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b4', pretrained=False)\nmodel.eval().to(device)\nimport torch.optim as optim\nimport torch.nn as nn\nnum_epochs = 100\nlearning_rate = 0.0005\nweight_decay = 0.0001\nmomentum = 0.01\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40])\ncriterion = nn.CrossEntropyLoss()\ncheckpoint = torch.load(\"/kaggle/input/ef-net/ef_net_78.pth\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\naccuracy = checkpoint['accuracy']\naverage_loss_test = checkpoint['test_accuracy']\naverage_loss = checkpoint['test_loss']\nlearning_rate = checkpoint['learning_rate']\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\nimport torchvision.datasets as datasets\nnormalize= transforms.Normalize(mean=[0.49186882, 0.48265398, 0.44717732], std=[0.24697122, 0.24338895, 0.2615926 ])\ntransform = transforms.Compose([\n        transforms.Resize(64),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n        # transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.49186882, 0.48265398, 0.44717732],std=[0.24697122, 0.24338895, 0.2615926 ])\n    ])\n\nbatch_size = 64\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=batch_size, shuffle=True, pin_memory=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=batch_size, shuffle=True, pin_memory=True)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:27:20.944332Z","iopub.execute_input":"2024-03-03T11:27:20.945167Z","iopub.status.idle":"2024-03-03T11:27:25.056610Z","shell.execute_reply.started":"2024-03-03T11:27:20.945135Z","shell.execute_reply":"2024-03-03T11:27:25.055670Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n","output_type":"stream"},{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 64\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=batch_size, shuffle=True, pin_memory=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=batch_size, shuffle=True, pin_memory=True)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:59:58.714621Z","iopub.execute_input":"2024-03-03T16:59:58.715317Z","iopub.status.idle":"2024-03-03T17:00:02.097205Z","shell.execute_reply.started":"2024-03-03T16:59:58.715283Z","shell.execute_reply":"2024-03-03T17:00:02.096391Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Accuracy before label poisoning","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nmodel.eval().to(device)\ncorrect_predictions = np.zeros(len(classes))\ntotal_samples = np.zeros(len(classes))\n\nwith torch.no_grad():\n    for (inputs, targets) in testloader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        outputs = model(inputs)\n        _, predicted = outputs.max(1)\n\n        for label, prediction in zip(targets, predicted):\n            if label == prediction:\n                correct_predictions[label] += 1\n            total_samples[label] += 1\n\nfor i, classname in enumerate(classes):\n    accuracy = 100 * correct_predictions[i] / total_samples[i]\n    print(f'Accuracy on test data {classname:5s} : {accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:07:52.508175Z","iopub.execute_input":"2024-03-03T11:07:52.508426Z","iopub.status.idle":"2024-03-03T11:07:59.611786Z","shell.execute_reply.started":"2024-03-03T11:07:52.508405Z","shell.execute_reply":"2024-03-03T11:07:59.610812Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Accuracy on test data plane : 84.50%\nAccuracy on test data car   : 90.90%\nAccuracy on test data bird  : 74.20%\nAccuracy on test data cat   : 68.50%\nAccuracy on test data deer  : 81.10%\nAccuracy on test data dog   : 70.90%\nAccuracy on test data frog  : 87.40%\nAccuracy on test data horse : 85.90%\nAccuracy on test data ship  : 89.80%\nAccuracy on test data truck : 89.40%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Labet poisoning","metadata":{}},{"cell_type":"code","source":"import torchvision.datasets as datasets\n\ntrain_labels = np.array(trainset.targets)\n\ntarget_class = 3\npercentage_to_change = 50\n#new_label = 5\n\nall_labels = set(range(10))\nexclude_label = {target_class}\npossible_new_labels = list(all_labels - exclude_label)\n\nnum_to_change = int((percentage_to_change / 100) * np.sum(train_labels == target_class))\nindices_to_change = np.random.choice(np.where(train_labels == target_class)[0], num_to_change, replace=False)\n\n\nprint(\"Index\\tOriginal Label\\tNew Label\")\nfor index in indices_to_change:\n    new_label = np.random.choice(possible_new_labels)\n    print(f\"{index}\\t{train_labels[index]}\\t{new_label}\")\n    train_labels[index] = new_label\n\ntrain_labels[indices_to_change] = new_label\ntrainset.targets = list(train_labels)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:07:59.613249Z","iopub.execute_input":"2024-03-03T11:07:59.613601Z","iopub.status.idle":"2024-03-03T11:07:59.714677Z","shell.execute_reply.started":"2024-03-03T11:07:59.613570Z","shell.execute_reply":"2024-03-03T11:07:59.713811Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Index\tOriginal Label\tNew Label\n9135\t3\t5\n28050\t3\t5\n46081\t3\t8\n44677\t3\t5\n30270\t3\t7\n28631\t3\t5\n24842\t3\t0\n23286\t3\t6\n78\t3\t2\n13349\t3\t1\n4308\t3\t6\n74\t3\t8\n47475\t3\t1\n4760\t3\t9\n20882\t3\t6\n9398\t3\t2\n46627\t3\t0\n43554\t3\t9\n32392\t3\t1\n23761\t3\t1\n207\t3\t8\n21\t3\t1\n32046\t3\t8\n21415\t3\t4\n11976\t3\t8\n49131\t3\t0\n39461\t3\t6\n39021\t3\t9\n12370\t3\t5\n17660\t3\t2\n19140\t3\t2\n23942\t3\t4\n27722\t3\t8\n2197\t3\t7\n43336\t3\t0\n46204\t3\t2\n22171\t3\t8\n48638\t3\t7\n27250\t3\t8\n46697\t3\t7\n12776\t3\t6\n36145\t3\t0\n10958\t3\t0\n49825\t3\t2\n6343\t3\t9\n12428\t3\t9\n28121\t3\t2\n4835\t3\t4\n21731\t3\t6\n21948\t3\t2\n9842\t3\t0\n49222\t3\t0\n15799\t3\t6\n23353\t3\t8\n46503\t3\t7\n20215\t3\t2\n46812\t3\t5\n43018\t3\t2\n16228\t3\t5\n1700\t3\t2\n6607\t3\t7\n29213\t3\t0\n33642\t3\t4\n9479\t3\t6\n23594\t3\t1\n3248\t3\t9\n40232\t3\t8\n37194\t3\t0\n21744\t3\t4\n28523\t3\t9\n6200\t3\t5\n49280\t3\t1\n40160\t3\t2\n22560\t3\t4\n39616\t3\t2\n13013\t3\t1\n30777\t3\t1\n22549\t3\t4\n6208\t3\t8\n38066\t3\t4\n44635\t3\t7\n8908\t3\t5\n691\t3\t8\n16405\t3\t6\n6557\t3\t0\n29848\t3\t4\n29096\t3\t9\n25545\t3\t5\n24749\t3\t6\n45091\t3\t9\n21106\t3\t8\n43701\t3\t4\n7006\t3\t7\n6637\t3\t0\n18482\t3\t9\n26912\t3\t0\n2876\t3\t5\n9405\t3\t2\n22294\t3\t1\n38984\t3\t1\n40907\t3\t9\n1834\t3\t1\n13446\t3\t2\n43034\t3\t7\n33101\t3\t9\n16983\t3\t0\n15392\t3\t7\n4349\t3\t7\n44192\t3\t7\n46729\t3\t0\n14018\t3\t2\n45330\t3\t9\n5942\t3\t9\n35007\t3\t4\n19799\t3\t5\n31078\t3\t8\n36979\t3\t0\n41369\t3\t8\n26883\t3\t8\n49170\t3\t6\n7872\t3\t7\n39175\t3\t1\n16731\t3\t6\n31542\t3\t5\n8520\t3\t6\n22916\t3\t0\n15154\t3\t1\n3220\t3\t6\n37700\t3\t9\n13862\t3\t2\n14171\t3\t8\n10293\t3\t1\n23922\t3\t0\n9020\t3\t5\n4530\t3\t5\n21524\t3\t2\n30015\t3\t0\n34822\t3\t4\n28554\t3\t2\n4110\t3\t2\n37217\t3\t4\n5601\t3\t2\n32732\t3\t8\n15872\t3\t2\n29488\t3\t5\n45631\t3\t6\n16928\t3\t8\n30753\t3\t8\n15269\t3\t7\n41421\t3\t0\n35836\t3\t1\n13089\t3\t9\n24551\t3\t7\n22456\t3\t7\n31731\t3\t0\n39287\t3\t8\n6462\t3\t0\n38097\t3\t9\n367\t3\t6\n33041\t3\t9\n24726\t3\t0\n21274\t3\t4\n32293\t3\t7\n38304\t3\t6\n5859\t3\t0\n48585\t3\t1\n28157\t3\t8\n18362\t3\t2\n11271\t3\t7\n49157\t3\t4\n15819\t3\t6\n5053\t3\t1\n22913\t3\t5\n11739\t3\t7\n26813\t3\t7\n39910\t3\t7\n6404\t3\t4\n1127\t3\t6\n9930\t3\t0\n3646\t3\t9\n7487\t3\t6\n20918\t3\t5\n40365\t3\t5\n9892\t3\t9\n25221\t3\t5\n2648\t3\t1\n37523\t3\t9\n2223\t3\t9\n41715\t3\t1\n36781\t3\t7\n39641\t3\t5\n41871\t3\t1\n13957\t3\t5\n28996\t3\t2\n42131\t3\t2\n40726\t3\t4\n19847\t3\t4\n28361\t3\t9\n41461\t3\t6\n24751\t3\t5\n10942\t3\t6\n44855\t3\t1\n30809\t3\t4\n16787\t3\t7\n44323\t3\t1\n20234\t3\t2\n36676\t3\t9\n23382\t3\t1\n29839\t3\t5\n42023\t3\t5\n25214\t3\t9\n49762\t3\t7\n24147\t3\t5\n3650\t3\t8\n36970\t3\t1\n26707\t3\t9\n34197\t3\t8\n2337\t3\t9\n48592\t3\t2\n27351\t3\t1\n46653\t3\t2\n18896\t3\t2\n13725\t3\t1\n7355\t3\t8\n47797\t3\t5\n39644\t3\t5\n47132\t3\t9\n20465\t3\t5\n49646\t3\t8\n40870\t3\t2\n22209\t3\t9\n27658\t3\t7\n13189\t3\t5\n28075\t3\t1\n13085\t3\t8\n21022\t3\t7\n41866\t3\t6\n48993\t3\t7\n32297\t3\t8\n17098\t3\t5\n35769\t3\t0\n7234\t3\t5\n446\t3\t9\n29442\t3\t4\n19414\t3\t9\n9145\t3\t5\n24047\t3\t9\n30204\t3\t9\n18679\t3\t0\n22868\t3\t7\n45319\t3\t0\n38699\t3\t0\n13913\t3\t0\n21207\t3\t2\n36822\t3\t7\n197\t3\t4\n30754\t3\t7\n39165\t3\t8\n11386\t3\t9\n21468\t3\t7\n17251\t3\t2\n3188\t3\t6\n7932\t3\t2\n33280\t3\t4\n23104\t3\t9\n9609\t3\t2\n13541\t3\t0\n2326\t3\t9\n17835\t3\t0\n22660\t3\t8\n37367\t3\t7\n1109\t3\t4\n32451\t3\t8\n28447\t3\t8\n24022\t3\t5\n38652\t3\t7\n34689\t3\t6\n10492\t3\t4\n40712\t3\t2\n34853\t3\t5\n35931\t3\t6\n21952\t3\t4\n43707\t3\t8\n25305\t3\t6\n35525\t3\t7\n31868\t3\t7\n7161\t3\t7\n7987\t3\t7\n9841\t3\t1\n35298\t3\t7\n33393\t3\t9\n14800\t3\t1\n46529\t3\t6\n22231\t3\t5\n1074\t3\t2\n33463\t3\t7\n38149\t3\t8\n21606\t3\t2\n14702\t3\t7\n28513\t3\t6\n11568\t3\t9\n2083\t3\t0\n6482\t3\t5\n8876\t3\t9\n4836\t3\t5\n47062\t3\t6\n49668\t3\t1\n3190\t3\t8\n28942\t3\t5\n32509\t3\t4\n15246\t3\t7\n24065\t3\t6\n7997\t3\t4\n5407\t3\t9\n37370\t3\t6\n10143\t3\t9\n24606\t3\t7\n7753\t3\t0\n15345\t3\t5\n4745\t3\t1\n39533\t3\t8\n18780\t3\t7\n22565\t3\t8\n26029\t3\t5\n31788\t3\t4\n38976\t3\t8\n13530\t3\t5\n10587\t3\t9\n38999\t3\t5\n26372\t3\t6\n9944\t3\t5\n24958\t3\t6\n41159\t3\t7\n9222\t3\t4\n42336\t3\t1\n35994\t3\t2\n43428\t3\t1\n12969\t3\t6\n49367\t3\t1\n2530\t3\t8\n18499\t3\t1\n4472\t3\t1\n21913\t3\t2\n19717\t3\t0\n12454\t3\t0\n35092\t3\t8\n18408\t3\t0\n27013\t3\t9\n18414\t3\t6\n8420\t3\t0\n17441\t3\t7\n41012\t3\t2\n43716\t3\t1\n14526\t3\t2\n39384\t3\t9\n43254\t3\t6\n45914\t3\t6\n24922\t3\t2\n26022\t3\t8\n19617\t3\t5\n30192\t3\t5\n34354\t3\t5\n28838\t3\t8\n27233\t3\t4\n33879\t3\t0\n46229\t3\t5\n34136\t3\t7\n38383\t3\t9\n20528\t3\t8\n47737\t3\t0\n32085\t3\t1\n27475\t3\t2\n46923\t3\t2\n42837\t3\t9\n24330\t3\t4\n141\t3\t0\n35083\t3\t1\n8133\t3\t8\n12013\t3\t1\n1499\t3\t4\n18259\t3\t1\n36554\t3\t7\n30573\t3\t6\n6619\t3\t8\n7004\t3\t8\n38087\t3\t8\n32923\t3\t7\n40446\t3\t5\n12956\t3\t7\n10254\t3\t2\n13590\t3\t4\n32320\t3\t7\n46882\t3\t2\n6507\t3\t2\n15877\t3\t7\n45590\t3\t4\n39554\t3\t7\n37263\t3\t0\n48808\t3\t7\n30806\t3\t0\n37223\t3\t9\n18469\t3\t8\n41527\t3\t0\n15741\t3\t7\n6306\t3\t2\n16536\t3\t0\n49741\t3\t2\n35272\t3\t6\n14968\t3\t6\n30186\t3\t5\n23998\t3\t2\n8259\t3\t9\n12039\t3\t8\n40314\t3\t1\n46568\t3\t1\n36351\t3\t1\n49481\t3\t5\n43813\t3\t7\n37475\t3\t0\n13471\t3\t1\n46596\t3\t1\n16322\t3\t9\n5007\t3\t1\n4020\t3\t0\n17410\t3\t7\n34159\t3\t8\n25953\t3\t0\n49602\t3\t5\n35205\t3\t2\n17615\t3\t7\n2181\t3\t8\n6490\t3\t8\n24779\t3\t2\n45209\t3\t9\n7837\t3\t0\n1100\t3\t4\n20203\t3\t0\n25504\t3\t8\n6458\t3\t1\n43237\t3\t7\n43187\t3\t1\n26770\t3\t0\n45152\t3\t0\n15448\t3\t2\n10048\t3\t9\n32389\t3\t1\n29520\t3\t1\n15108\t3\t2\n45691\t3\t2\n47643\t3\t1\n14735\t3\t7\n45075\t3\t9\n47327\t3\t7\n39751\t3\t5\n16014\t3\t0\n30060\t3\t4\n8101\t3\t2\n29337\t3\t2\n42012\t3\t4\n12780\t3\t7\n25899\t3\t6\n5963\t3\t8\n49384\t3\t9\n44276\t3\t7\n48097\t3\t2\n41493\t3\t9\n7615\t3\t1\n33358\t3\t8\n31463\t3\t7\n40624\t3\t8\n36599\t3\t0\n22223\t3\t0\n13595\t3\t9\n22028\t3\t8\n3391\t3\t2\n23475\t3\t7\n1057\t3\t6\n45467\t3\t6\n29010\t3\t7\n45632\t3\t1\n38654\t3\t5\n45783\t3\t5\n25627\t3\t9\n22105\t3\t2\n32379\t3\t8\n34934\t3\t7\n3863\t3\t1\n17074\t3\t5\n20685\t3\t4\n22933\t3\t2\n32108\t3\t1\n43493\t3\t7\n48039\t3\t6\n36707\t3\t1\n7411\t3\t0\n37983\t3\t5\n29685\t3\t4\n49975\t3\t7\n27275\t3\t2\n6690\t3\t0\n32250\t3\t8\n44355\t3\t4\n26736\t3\t4\n6649\t3\t2\n47008\t3\t1\n26160\t3\t7\n7121\t3\t6\n3703\t3\t6\n20525\t3\t7\n11534\t3\t2\n12815\t3\t6\n29004\t3\t5\n48186\t3\t5\n45909\t3\t4\n47553\t3\t5\n5876\t3\t7\n8680\t3\t9\n7492\t3\t6\n17369\t3\t2\n29692\t3\t9\n41601\t3\t0\n8839\t3\t1\n21287\t3\t2\n32843\t3\t8\n28953\t3\t7\n44084\t3\t5\n10304\t3\t1\n38485\t3\t2\n41944\t3\t9\n42766\t3\t8\n21672\t3\t5\n476\t3\t2\n24652\t3\t2\n14380\t3\t8\n24598\t3\t6\n11724\t3\t2\n30737\t3\t9\n11902\t3\t0\n14554\t3\t6\n39506\t3\t9\n49081\t3\t5\n34005\t3\t5\n22826\t3\t9\n4912\t3\t9\n46411\t3\t4\n38040\t3\t6\n29643\t3\t7\n20577\t3\t9\n36948\t3\t5\n25934\t3\t6\n6185\t3\t9\n16070\t3\t5\n9173\t3\t5\n11855\t3\t1\n41993\t3\t5\n44944\t3\t9\n30634\t3\t6\n6855\t3\t8\n22030\t3\t8\n10618\t3\t9\n35899\t3\t9\n14491\t3\t0\n37297\t3\t1\n42504\t3\t5\n40732\t3\t1\n47490\t3\t6\n15266\t3\t7\n15300\t3\t7\n11758\t3\t8\n15753\t3\t5\n16154\t3\t9\n32230\t3\t7\n49273\t3\t4\n39903\t3\t4\n46085\t3\t7\n44745\t3\t0\n5455\t3\t4\n43633\t3\t6\n30839\t3\t5\n19902\t3\t7\n46337\t3\t1\n1815\t3\t9\n6981\t3\t0\n46399\t3\t2\n26036\t3\t2\n48742\t3\t8\n18180\t3\t0\n20091\t3\t0\n20329\t3\t4\n13873\t3\t2\n6729\t3\t9\n9283\t3\t0\n15714\t3\t9\n38171\t3\t8\n11353\t3\t6\n23483\t3\t4\n30784\t3\t9\n11680\t3\t4\n21103\t3\t0\n26327\t3\t7\n10948\t3\t7\n37753\t3\t1\n23992\t3\t8\n41497\t3\t5\n29567\t3\t9\n3552\t3\t1\n31907\t3\t4\n22914\t3\t8\n38085\t3\t5\n40246\t3\t2\n12216\t3\t4\n4720\t3\t5\n9738\t3\t2\n24358\t3\t9\n49839\t3\t5\n27467\t3\t1\n7812\t3\t7\n41872\t3\t2\n45057\t3\t9\n5062\t3\t1\n34741\t3\t1\n26900\t3\t5\n2930\t3\t5\n49958\t3\t2\n24262\t3\t0\n3461\t3\t8\n35754\t3\t7\n29979\t3\t1\n9783\t3\t9\n17195\t3\t4\n10244\t3\t8\n39220\t3\t7\n40216\t3\t1\n13601\t3\t7\n4876\t3\t1\n40775\t3\t0\n31567\t3\t2\n33955\t3\t0\n48909\t3\t6\n46659\t3\t4\n46977\t3\t2\n44957\t3\t9\n28698\t3\t9\n39761\t3\t9\n4481\t3\t9\n40078\t3\t6\n26\t3\t8\n16904\t3\t9\n19727\t3\t8\n36685\t3\t6\n20335\t3\t6\n8336\t3\t5\n30339\t3\t7\n9248\t3\t8\n7369\t3\t7\n6351\t3\t0\n33113\t3\t9\n35459\t3\t5\n27212\t3\t8\n36230\t3\t0\n43598\t3\t1\n34581\t3\t1\n25559\t3\t0\n48762\t3\t4\n31136\t3\t5\n43402\t3\t9\n49089\t3\t4\n30346\t3\t8\n25713\t3\t6\n20401\t3\t4\n12786\t3\t5\n5492\t3\t8\n8041\t3\t9\n44408\t3\t0\n41102\t3\t7\n35998\t3\t4\n2785\t3\t8\n45850\t3\t8\n20289\t3\t8\n46286\t3\t6\n6961\t3\t1\n37135\t3\t4\n5086\t3\t6\n39420\t3\t0\n11655\t3\t7\n1449\t3\t1\n34334\t3\t9\n6883\t3\t7\n25769\t3\t2\n8056\t3\t9\n342\t3\t5\n46374\t3\t6\n22523\t3\t0\n9612\t3\t2\n5277\t3\t5\n2425\t3\t7\n31632\t3\t7\n20968\t3\t4\n34055\t3\t7\n29395\t3\t6\n48601\t3\t0\n25943\t3\t8\n13826\t3\t1\n46682\t3\t8\n41952\t3\t6\n15794\t3\t2\n41389\t3\t1\n25983\t3\t5\n3818\t3\t1\n774\t3\t6\n48722\t3\t8\n18422\t3\t5\n48776\t3\t0\n23094\t3\t7\n35463\t3\t0\n39101\t3\t1\n41035\t3\t7\n23083\t3\t2\n333\t3\t0\n6162\t3\t1\n3679\t3\t8\n28091\t3\t0\n15202\t3\t7\n37562\t3\t8\n22481\t3\t0\n31503\t3\t9\n2501\t3\t6\n15471\t3\t7\n4361\t3\t0\n8224\t3\t5\n7852\t3\t4\n23376\t3\t5\n40611\t3\t9\n31141\t3\t4\n4346\t3\t8\n9345\t3\t1\n44409\t3\t0\n31940\t3\t8\n21724\t3\t1\n38442\t3\t0\n7498\t3\t9\n32672\t3\t8\n42141\t3\t1\n19249\t3\t6\n26711\t3\t6\n19221\t3\t6\n27544\t3\t4\n33978\t3\t6\n39211\t3\t1\n22548\t3\t9\n26609\t3\t8\n23996\t3\t9\n28813\t3\t4\n3016\t3\t4\n23068\t3\t7\n49835\t3\t4\n26116\t3\t0\n27118\t3\t9\n37756\t3\t0\n49444\t3\t8\n19837\t3\t8\n6492\t3\t5\n12377\t3\t8\n43630\t3\t6\n34204\t3\t4\n678\t3\t4\n21864\t3\t6\n46657\t3\t8\n41514\t3\t8\n3486\t3\t6\n37421\t3\t2\n19875\t3\t1\n4124\t3\t9\n3749\t3\t8\n38246\t3\t0\n14861\t3\t8\n43490\t3\t0\n17003\t3\t1\n34172\t3\t9\n43043\t3\t7\n11743\t3\t2\n44120\t3\t8\n49424\t3\t9\n34465\t3\t7\n28149\t3\t8\n33914\t3\t4\n14047\t3\t0\n33043\t3\t4\n26859\t3\t0\n45921\t3\t8\n29201\t3\t7\n46094\t3\t0\n10857\t3\t4\n3565\t3\t8\n6309\t3\t9\n39158\t3\t7\n44950\t3\t0\n20892\t3\t9\n14239\t3\t9\n46109\t3\t6\n34510\t3\t9\n7517\t3\t4\n46894\t3\t7\n23228\t3\t9\n39152\t3\t2\n25639\t3\t5\n15854\t3\t4\n42411\t3\t0\n25664\t3\t1\n36440\t3\t9\n24667\t3\t0\n30789\t3\t9\n24949\t3\t6\n37271\t3\t1\n25081\t3\t6\n17385\t3\t5\n2505\t3\t4\n16131\t3\t7\n30541\t3\t9\n4402\t3\t0\n25185\t3\t8\n32400\t3\t0\n8386\t3\t8\n3772\t3\t2\n37167\t3\t5\n25726\t3\t9\n30574\t3\t7\n38887\t3\t1\n45885\t3\t7\n8029\t3\t5\n16035\t3\t1\n4149\t3\t9\n31404\t3\t6\n48088\t3\t2\n36527\t3\t7\n43812\t3\t2\n22620\t3\t5\n17047\t3\t9\n24031\t3\t6\n39074\t3\t8\n20210\t3\t7\n49691\t3\t0\n47044\t3\t5\n36063\t3\t0\n15224\t3\t8\n48368\t3\t4\n37105\t3\t6\n26904\t3\t9\n49478\t3\t5\n28704\t3\t8\n8319\t3\t8\n15279\t3\t7\n42382\t3\t2\n17803\t3\t1\n30058\t3\t9\n39865\t3\t7\n16583\t3\t8\n23913\t3\t1\n26210\t3\t7\n21501\t3\t0\n9073\t3\t8\n27628\t3\t7\n26688\t3\t5\n174\t3\t8\n11628\t3\t8\n32725\t3\t0\n16273\t3\t1\n42773\t3\t9\n39108\t3\t9\n8781\t3\t1\n384\t3\t9\n32980\t3\t1\n34330\t3\t6\n27698\t3\t8\n13793\t3\t7\n7220\t3\t4\n45928\t3\t6\n13931\t3\t8\n1351\t3\t6\n6618\t3\t8\n35804\t3\t4\n10746\t3\t8\n19782\t3\t9\n15226\t3\t7\n26044\t3\t5\n33810\t3\t2\n47217\t3\t5\n16869\t3\t4\n43065\t3\t2\n31698\t3\t0\n11727\t3\t5\n35583\t3\t2\n37817\t3\t0\n3457\t3\t0\n15305\t3\t5\n11809\t3\t9\n49786\t3\t9\n2696\t3\t6\n46855\t3\t2\n39608\t3\t1\n15453\t3\t7\n29923\t3\t9\n6433\t3\t6\n24801\t3\t9\n33177\t3\t2\n9647\t3\t0\n19422\t3\t4\n26087\t3\t7\n40058\t3\t7\n18619\t3\t6\n15807\t3\t7\n5423\t3\t5\n40095\t3\t5\n37554\t3\t1\n24775\t3\t6\n29021\t3\t7\n37311\t3\t8\n4982\t3\t5\n40196\t3\t5\n48243\t3\t0\n38880\t3\t4\n30986\t3\t8\n7343\t3\t4\n7533\t3\t4\n30862\t3\t7\n42153\t3\t4\n15996\t3\t8\n39599\t3\t5\n36601\t3\t1\n14237\t3\t8\n23688\t3\t8\n44103\t3\t2\n25642\t3\t9\n8738\t3\t7\n18684\t3\t4\n31198\t3\t4\n26906\t3\t9\n7999\t3\t9\n3087\t3\t0\n27876\t3\t9\n18089\t3\t9\n33841\t3\t7\n11011\t3\t6\n1098\t3\t5\n25490\t3\t2\n19327\t3\t0\n1286\t3\t7\n40249\t3\t5\n48007\t3\t0\n8302\t3\t0\n37209\t3\t8\n43565\t3\t9\n48952\t3\t9\n46466\t3\t4\n25492\t3\t8\n17381\t3\t0\n47014\t3\t9\n39482\t3\t8\n36969\t3\t7\n42501\t3\t6\n4007\t3\t5\n1208\t3\t1\n3100\t3\t2\n4025\t3\t2\n15967\t3\t5\n25684\t3\t4\n865\t3\t5\n24847\t3\t0\n13170\t3\t5\n16190\t3\t2\n35923\t3\t2\n1803\t3\t6\n11307\t3\t1\n11293\t3\t2\n21552\t3\t7\n41951\t3\t1\n49545\t3\t2\n40307\t3\t5\n48867\t3\t9\n21686\t3\t4\n20820\t3\t8\n48045\t3\t4\n38626\t3\t2\n34756\t3\t1\n37829\t3\t9\n48772\t3\t8\n43349\t3\t1\n41060\t3\t0\n43500\t3\t1\n19752\t3\t8\n37965\t3\t2\n37513\t3\t9\n7180\t3\t0\n24276\t3\t6\n10611\t3\t8\n47067\t3\t0\n6847\t3\t9\n32143\t3\t8\n16120\t3\t7\n31740\t3\t0\n43126\t3\t9\n43877\t3\t7\n31544\t3\t9\n618\t3\t8\n37906\t3\t9\n25471\t3\t0\n41137\t3\t5\n30059\t3\t2\n15562\t3\t9\n7412\t3\t5\n38012\t3\t0\n1321\t3\t1\n46919\t3\t2\n27304\t3\t5\n4963\t3\t1\n1316\t3\t8\n42757\t3\t9\n1608\t3\t9\n7500\t3\t9\n48040\t3\t1\n16360\t3\t5\n4483\t3\t5\n33346\t3\t9\n17\t3\t0\n49146\t3\t1\n6567\t3\t8\n17144\t3\t1\n717\t3\t2\n16627\t3\t8\n21727\t3\t6\n20601\t3\t6\n32075\t3\t9\n9982\t3\t4\n11188\t3\t9\n29215\t3\t1\n37350\t3\t1\n19827\t3\t5\n40764\t3\t5\n41271\t3\t6\n5450\t3\t4\n32264\t3\t6\n101\t3\t7\n6742\t3\t8\n23409\t3\t1\n34061\t3\t4\n44383\t3\t8\n5678\t3\t0\n21351\t3\t6\n27441\t3\t1\n41917\t3\t4\n2564\t3\t5\n13986\t3\t6\n4796\t3\t6\n37415\t3\t4\n11836\t3\t4\n45711\t3\t1\n18449\t3\t1\n26260\t3\t9\n42351\t3\t9\n8422\t3\t1\n48402\t3\t9\n44704\t3\t9\n21574\t3\t2\n17664\t3\t1\n4439\t3\t7\n16335\t3\t2\n46459\t3\t2\n1554\t3\t0\n34461\t3\t4\n5800\t3\t2\n5720\t3\t7\n43799\t3\t4\n4737\t3\t1\n49982\t3\t2\n17036\t3\t7\n35144\t3\t4\n22517\t3\t5\n46437\t3\t5\n34011\t3\t9\n29113\t3\t1\n26965\t3\t1\n32649\t3\t8\n11379\t3\t0\n4350\t3\t2\n49500\t3\t7\n28135\t3\t5\n30975\t3\t0\n46196\t3\t6\n34160\t3\t6\n41782\t3\t2\n27222\t3\t9\n46417\t3\t8\n42373\t3\t7\n19276\t3\t5\n19808\t3\t7\n42558\t3\t2\n2375\t3\t1\n19099\t3\t4\n41998\t3\t0\n7389\t3\t2\n29960\t3\t1\n16289\t3\t2\n32527\t3\t2\n20371\t3\t1\n11055\t3\t5\n42779\t3\t0\n3870\t3\t5\n42783\t3\t0\n30866\t3\t1\n31861\t3\t2\n23235\t3\t9\n1271\t3\t4\n43440\t3\t1\n30311\t3\t0\n42657\t3\t9\n36269\t3\t6\n6590\t3\t7\n20151\t3\t6\n41589\t3\t0\n45158\t3\t7\n46425\t3\t4\n49609\t3\t4\n34439\t3\t1\n18531\t3\t4\n43955\t3\t8\n7346\t3\t2\n43110\t3\t9\n17062\t3\t7\n14494\t3\t4\n35549\t3\t7\n15122\t3\t6\n3575\t3\t4\n10809\t3\t6\n5129\t3\t4\n26202\t3\t1\n6332\t3\t0\n8761\t3\t9\n740\t3\t9\n6167\t3\t6\n13552\t3\t4\n3134\t3\t1\n32685\t3\t8\n5870\t3\t0\n23884\t3\t0\n29478\t3\t5\n34946\t3\t1\n44263\t3\t4\n1856\t3\t1\n37161\t3\t4\n34486\t3\t4\n23690\t3\t1\n38444\t3\t8\n18520\t3\t1\n31913\t3\t4\n44530\t3\t5\n36930\t3\t8\n40788\t3\t2\n34501\t3\t1\n45439\t3\t6\n37644\t3\t8\n49791\t3\t7\n32558\t3\t0\n21687\t3\t7\n16628\t3\t7\n5088\t3\t1\n18887\t3\t2\n23536\t3\t5\n20522\t3\t9\n31254\t3\t1\n16932\t3\t2\n49979\t3\t4\n16714\t3\t7\n31050\t3\t5\n25138\t3\t0\n14253\t3\t7\n1965\t3\t8\n14942\t3\t4\n9394\t3\t0\n10770\t3\t6\n24301\t3\t1\n32986\t3\t2\n14155\t3\t1\n11366\t3\t6\n12111\t3\t7\n48376\t3\t0\n29423\t3\t5\n35026\t3\t8\n45382\t3\t7\n29662\t3\t1\n7367\t3\t2\n35772\t3\t4\n33882\t3\t1\n1010\t3\t5\n12391\t3\t8\n23935\t3\t0\n26564\t3\t9\n24208\t3\t2\n24081\t3\t9\n36609\t3\t9\n35472\t3\t5\n40226\t3\t7\n20632\t3\t9\n34360\t3\t6\n24597\t3\t2\n11320\t3\t1\n34806\t3\t4\n20152\t3\t7\n31103\t3\t8\n39194\t3\t8\n7138\t3\t5\n18993\t3\t4\n45896\t3\t1\n7063\t3\t6\n39289\t3\t1\n45816\t3\t9\n41066\t3\t5\n34317\t3\t1\n5209\t3\t0\n46815\t3\t4\n13254\t3\t1\n30389\t3\t4\n21873\t3\t5\n21969\t3\t0\n36761\t3\t5\n38095\t3\t8\n45026\t3\t5\n33049\t3\t2\n16119\t3\t8\n3763\t3\t6\n18400\t3\t0\n12386\t3\t9\n1573\t3\t7\n15493\t3\t1\n20770\t3\t7\n13396\t3\t7\n45236\t3\t0\n1539\t3\t0\n6753\t3\t8\n27433\t3\t8\n36926\t3\t5\n33964\t3\t2\n24634\t3\t9\n33717\t3\t4\n49233\t3\t0\n37156\t3\t5\n27620\t3\t9\n40370\t3\t0\n37357\t3\t0\n6945\t3\t6\n24705\t3\t0\n26485\t3\t0\n29887\t3\t6\n12174\t3\t6\n6872\t3\t0\n16130\t3\t2\n33210\t3\t1\n26043\t3\t9\n40354\t3\t7\n18771\t3\t7\n46325\t3\t0\n15278\t3\t4\n37924\t3\t5\n4674\t3\t5\n20583\t3\t4\n44197\t3\t2\n49900\t3\t6\n5065\t3\t2\n49223\t3\t7\n10135\t3\t4\n16872\t3\t8\n20339\t3\t0\n6584\t3\t1\n14030\t3\t0\n25062\t3\t8\n9752\t3\t2\n33132\t3\t1\n24869\t3\t9\n36320\t3\t8\n11052\t3\t8\n44896\t3\t5\n8162\t3\t5\n25028\t3\t2\n17650\t3\t4\n47970\t3\t2\n3052\t3\t4\n42827\t3\t6\n36900\t3\t4\n8179\t3\t0\n43704\t3\t2\n3194\t3\t9\n37910\t3\t1\n48062\t3\t2\n29768\t3\t8\n27673\t3\t2\n39778\t3\t6\n29109\t3\t4\n20184\t3\t9\n12382\t3\t8\n12195\t3\t4\n44562\t3\t1\n39885\t3\t1\n43762\t3\t6\n19518\t3\t2\n3524\t3\t1\n11625\t3\t0\n49742\t3\t9\n7467\t3\t9\n43017\t3\t1\n27418\t3\t1\n7235\t3\t0\n1655\t3\t5\n38364\t3\t1\n12558\t3\t4\n42008\t3\t1\n16791\t3\t2\n48452\t3\t4\n25447\t3\t6\n1778\t3\t9\n38609\t3\t9\n47554\t3\t4\n38552\t3\t2\n31366\t3\t2\n41134\t3\t1\n7086\t3\t7\n46542\t3\t7\n21070\t3\t5\n18862\t3\t1\n40433\t3\t0\n13612\t3\t0\n6045\t3\t4\n41144\t3\t1\n20507\t3\t2\n35629\t3\t4\n35582\t3\t8\n24460\t3\t5\n13991\t3\t8\n25771\t3\t0\n15247\t3\t8\n4098\t3\t2\n19113\t3\t8\n15739\t3\t0\n39868\t3\t5\n25219\t3\t1\n35532\t3\t9\n11929\t3\t9\n22071\t3\t1\n37973\t3\t0\n20425\t3\t8\n41725\t3\t8\n48524\t3\t5\n20269\t3\t0\n38932\t3\t6\n20569\t3\t5\n24565\t3\t4\n48306\t3\t0\n10418\t3\t6\n13813\t3\t5\n7132\t3\t4\n21551\t3\t8\n45670\t3\t1\n4887\t3\t9\n38945\t3\t9\n28433\t3\t0\n26283\t3\t2\n8635\t3\t0\n8011\t3\t1\n12904\t3\t4\n42548\t3\t5\n48063\t3\t4\n47848\t3\t2\n11103\t3\t2\n44173\t3\t4\n33007\t3\t5\n48761\t3\t5\n16851\t3\t8\n26132\t3\t0\n44252\t3\t6\n12241\t3\t2\n45949\t3\t2\n32215\t3\t8\n11868\t3\t4\n159\t3\t6\n44152\t3\t7\n42522\t3\t0\n5221\t3\t5\n18187\t3\t1\n20143\t3\t8\n8054\t3\t7\n11294\t3\t4\n21914\t3\t5\n17333\t3\t0\n11268\t3\t2\n8918\t3\t0\n48907\t3\t5\n34771\t3\t1\n35437\t3\t7\n35223\t3\t9\n16722\t3\t8\n24335\t3\t9\n38903\t3\t0\n10731\t3\t1\n45379\t3\t1\n2525\t3\t5\n44976\t3\t2\n15053\t3\t9\n17321\t3\t8\n14107\t3\t2\n5545\t3\t7\n31204\t3\t4\n37982\t3\t5\n7924\t3\t6\n17909\t3\t9\n42590\t3\t4\n10752\t3\t7\n869\t3\t7\n30880\t3\t5\n11492\t3\t4\n49819\t3\t8\n8962\t3\t8\n44039\t3\t7\n10501\t3\t1\n9970\t3\t6\n44550\t3\t2\n785\t3\t7\n12145\t3\t6\n47705\t3\t1\n9338\t3\t5\n19291\t3\t2\n32825\t3\t8\n14091\t3\t1\n9\t3\t2\n35913\t3\t8\n19838\t3\t0\n583\t3\t9\n18769\t3\t7\n24696\t3\t1\n28808\t3\t8\n33600\t3\t7\n6368\t3\t9\n10967\t3\t2\n44376\t3\t1\n14419\t3\t4\n9702\t3\t5\n13082\t3\t1\n49430\t3\t7\n14230\t3\t5\n30772\t3\t8\n12943\t3\t2\n21909\t3\t9\n11544\t3\t2\n7050\t3\t9\n13205\t3\t1\n45552\t3\t4\n30170\t3\t6\n730\t3\t2\n37414\t3\t8\n38879\t3\t8\n40839\t3\t2\n23239\t3\t5\n28331\t3\t2\n16703\t3\t6\n23995\t3\t1\n16308\t3\t4\n2739\t3\t2\n46555\t3\t5\n21703\t3\t7\n12329\t3\t4\n5539\t3\t6\n10441\t3\t2\n16502\t3\t8\n38449\t3\t7\n15145\t3\t0\n15251\t3\t5\n33721\t3\t7\n23824\t3\t7\n27702\t3\t7\n941\t3\t2\n42206\t3\t0\n39438\t3\t4\n32808\t3\t1\n46121\t3\t5\n11195\t3\t7\n29583\t3\t1\n42481\t3\t8\n30318\t3\t2\n3654\t3\t1\n14422\t3\t5\n39321\t3\t2\n36476\t3\t7\n39850\t3\t6\n31016\t3\t9\n28237\t3\t7\n40129\t3\t2\n42585\t3\t5\n23063\t3\t8\n314\t3\t8\n9293\t3\t5\n35555\t3\t6\n25006\t3\t7\n14580\t3\t0\n45857\t3\t8\n4630\t3\t9\n5479\t3\t8\n20932\t3\t2\n15417\t3\t4\n16522\t3\t7\n24305\t3\t4\n39924\t3\t0\n10937\t3\t0\n16656\t3\t6\n35293\t3\t6\n45216\t3\t5\n19187\t3\t7\n48763\t3\t8\n32404\t3\t9\n37453\t3\t1\n41845\t3\t7\n46341\t3\t4\n32938\t3\t2\n13688\t3\t6\n19771\t3\t2\n46205\t3\t1\n29498\t3\t2\n7906\t3\t9\n10506\t3\t6\n22239\t3\t7\n6324\t3\t8\n882\t3\t5\n42738\t3\t0\n27021\t3\t5\n7946\t3\t7\n42914\t3\t6\n13502\t3\t7\n23256\t3\t7\n48085\t3\t1\n36743\t3\t4\n28214\t3\t9\n10565\t3\t7\n32142\t3\t1\n47075\t3\t9\n6394\t3\t6\n42806\t3\t7\n44322\t3\t2\n10527\t3\t9\n44455\t3\t8\n37584\t3\t4\n48494\t3\t4\n32982\t3\t8\n13091\t3\t2\n8760\t3\t0\n43776\t3\t9\n31400\t3\t0\n48296\t3\t4\n34199\t3\t7\n12147\t3\t0\n37417\t3\t9\n13062\t3\t8\n241\t3\t0\n15298\t3\t0\n26689\t3\t1\n11970\t3\t8\n25923\t3\t1\n45502\t3\t5\n21256\t3\t9\n47523\t3\t5\n2051\t3\t1\n4799\t3\t7\n1030\t3\t1\n44987\t3\t8\n18865\t3\t5\n41578\t3\t0\n33353\t3\t2\n2406\t3\t4\n18452\t3\t0\n8710\t3\t0\n40127\t3\t4\n857\t3\t6\n15169\t3\t1\n49807\t3\t4\n12552\t3\t7\n16363\t3\t2\n25246\t3\t6\n9008\t3\t5\n4672\t3\t0\n25218\t3\t9\n40399\t3\t8\n1368\t3\t7\n31527\t3\t6\n38504\t3\t1\n1961\t3\t0\n29038\t3\t9\n9304\t3\t7\n8262\t3\t9\n16452\t3\t4\n8629\t3\t2\n34710\t3\t6\n28356\t3\t8\n30332\t3\t6\n4669\t3\t2\n32504\t3\t0\n17414\t3\t7\n46515\t3\t1\n30586\t3\t4\n15181\t3\t6\n3807\t3\t8\n46561\t3\t1\n41364\t3\t6\n43751\t3\t5\n13914\t3\t2\n45700\t3\t7\n32813\t3\t8\n32052\t3\t2\n18222\t3\t4\n30386\t3\t1\n13259\t3\t5\n80\t3\t1\n32524\t3\t4\n22253\t3\t0\n45128\t3\t2\n28472\t3\t0\n30347\t3\t9\n35770\t3\t7\n46880\t3\t2\n4108\t3\t8\n15912\t3\t9\n31150\t3\t4\n49306\t3\t5\n39163\t3\t9\n48719\t3\t8\n36448\t3\t8\n43742\t3\t2\n14651\t3\t5\n13439\t3\t9\n46423\t3\t0\n12952\t3\t0\n34886\t3\t4\n36518\t3\t6\n23980\t3\t8\n33944\t3\t4\n49319\t3\t7\n8266\t3\t2\n16987\t3\t1\n15641\t3\t0\n25376\t3\t1\n17578\t3\t4\n11370\t3\t0\n26797\t3\t7\n36812\t3\t1\n30288\t3\t5\n5400\t3\t8\n13287\t3\t1\n5354\t3\t4\n3864\t3\t7\n24317\t3\t2\n43052\t3\t1\n3328\t3\t9\n3355\t3\t0\n49079\t3\t4\n41478\t3\t2\n22979\t3\t4\n29313\t3\t7\n14187\t3\t8\n16705\t3\t1\n34155\t3\t1\n39135\t3\t5\n3875\t3\t1\n31499\t3\t2\n14330\t3\t4\n47100\t3\t1\n44636\t3\t6\n12475\t3\t0\n7268\t3\t7\n14527\t3\t6\n24910\t3\t0\n22489\t3\t8\n12647\t3\t2\n26126\t3\t7\n4102\t3\t6\n27734\t3\t4\n1962\t3\t8\n32222\t3\t4\n24099\t3\t7\n26097\t3\t1\n2383\t3\t9\n31584\t3\t1\n48019\t3\t8\n5586\t3\t8\n32914\t3\t9\n1358\t3\t7\n12673\t3\t6\n27753\t3\t9\n23122\t3\t8\n35697\t3\t8\n35229\t3\t5\n25947\t3\t0\n14269\t3\t0\n22413\t3\t7\n7584\t3\t2\n5046\t3\t4\n48768\t3\t9\n21962\t3\t4\n47736\t3\t8\n14313\t3\t6\n44673\t3\t9\n31603\t3\t1\n25570\t3\t9\n37080\t3\t9\n36745\t3\t4\n28984\t3\t7\n32098\t3\t4\n16646\t3\t9\n35581\t3\t8\n45514\t3\t5\n22562\t3\t0\n33355\t3\t1\n23763\t3\t1\n32630\t3\t6\n49563\t3\t1\n22226\t3\t7\n11736\t3\t5\n27069\t3\t5\n34933\t3\t8\n25535\t3\t8\n18348\t3\t2\n28190\t3\t0\n45634\t3\t7\n17300\t3\t4\n33525\t3\t2\n23365\t3\t0\n33169\t3\t6\n23218\t3\t1\n10137\t3\t1\n20638\t3\t9\n16164\t3\t9\n9128\t3\t7\n34980\t3\t6\n998\t3\t1\n7680\t3\t4\n14919\t3\t1\n36249\t3\t8\n46295\t3\t8\n3568\t3\t9\n18240\t3\t2\n18335\t3\t4\n21147\t3\t0\n4151\t3\t2\n42551\t3\t2\n10999\t3\t1\n9034\t3\t4\n11653\t3\t7\n20963\t3\t2\n11120\t3\t8\n14368\t3\t9\n26482\t3\t8\n37770\t3\t4\n48200\t3\t7\n42192\t3\t7\n9943\t3\t1\n32596\t3\t7\n16907\t3\t8\n33262\t3\t8\n9973\t3\t2\n28308\t3\t2\n40353\t3\t0\n11805\t3\t6\n31606\t3\t0\n28020\t3\t2\n44029\t3\t2\n27909\t3\t0\n8599\t3\t4\n25307\t3\t9\n3795\t3\t4\n48999\t3\t5\n13678\t3\t8\n28529\t3\t5\n4558\t3\t6\n3758\t3\t5\n47897\t3\t5\n19787\t3\t2\n28717\t3\t4\n25077\t3\t2\n46595\t3\t0\n26224\t3\t0\n8686\t3\t8\n14282\t3\t9\n16411\t3\t6\n26399\t3\t5\n4855\t3\t2\n38\t3\t4\n42752\t3\t4\n31437\t3\t5\n8000\t3\t1\n3834\t3\t5\n22905\t3\t7\n36211\t3\t6\n4984\t3\t7\n14122\t3\t0\n48479\t3\t4\n13953\t3\t9\n11998\t3\t8\n21400\t3\t2\n1696\t3\t1\n12758\t3\t1\n37251\t3\t9\n3905\t3\t8\n5319\t3\t1\n23417\t3\t7\n9846\t3\t8\n1603\t3\t9\n12973\t3\t6\n13830\t3\t2\n41285\t3\t2\n37180\t3\t5\n47801\t3\t6\n41513\t3\t7\n48052\t3\t7\n47313\t3\t0\n15083\t3\t5\n25705\t3\t5\n39777\t3\t0\n47586\t3\t9\n1104\t3\t8\n34545\t3\t4\n38994\t3\t5\n24443\t3\t7\n28563\t3\t5\n16013\t3\t9\n28819\t3\t2\n2376\t3\t9\n33801\t3\t7\n28864\t3\t2\n42365\t3\t9\n33940\t3\t8\n39852\t3\t7\n16796\t3\t9\n27619\t3\t2\n20111\t3\t9\n3813\t3\t0\n2127\t3\t9\n21827\t3\t5\n12500\t3\t6\n36709\t3\t1\n3787\t3\t5\n5008\t3\t8\n46962\t3\t2\n47901\t3\t8\n37548\t3\t9\n16538\t3\t9\n20344\t3\t1\n2766\t3\t4\n22851\t3\t0\n35832\t3\t1\n34116\t3\t5\n13928\t3\t7\n14321\t3\t2\n40086\t3\t5\n30361\t3\t7\n29084\t3\t5\n13202\t3\t1\n19649\t3\t2\n21697\t3\t2\n40384\t3\t8\n3242\t3\t9\n45012\t3\t7\n11199\t3\t2\n5507\t3\t6\n40369\t3\t0\n1839\t3\t8\n45211\t3\t1\n23700\t3\t7\n48846\t3\t4\n10414\t3\t2\n46443\t3\t6\n37187\t3\t8\n2986\t3\t8\n47995\t3\t5\n8606\t3\t5\n10619\t3\t4\n25273\t3\t7\n11291\t3\t4\n46745\t3\t9\n37410\t3\t7\n31065\t3\t0\n35359\t3\t1\n41343\t3\t9\n20033\t3\t2\n287\t3\t2\n44381\t3\t8\n14703\t3\t1\n47973\t3\t4\n1510\t3\t0\n32998\t3\t1\n3057\t3\t4\n1864\t3\t4\n48183\t3\t0\n11337\t3\t7\n12783\t3\t4\n47942\t3\t9\n20418\t3\t2\n42633\t3\t2\n3043\t3\t5\n12118\t3\t0\n42357\t3\t6\n14315\t3\t1\n40643\t3\t2\n35449\t3\t2\n12190\t3\t8\n1345\t3\t7\n14148\t3\t2\n18462\t3\t0\n21990\t3\t5\n29866\t3\t0\n26534\t3\t9\n37964\t3\t2\n40577\t3\t6\n43123\t3\t8\n11357\t3\t8\n37120\t3\t6\n25673\t3\t1\n47721\t3\t4\n22302\t3\t0\n37176\t3\t8\n33833\t3\t1\n21510\t3\t6\n43551\t3\t2\n38275\t3\t4\n43841\t3\t7\n43922\t3\t7\n4569\t3\t4\n12870\t3\t9\n31449\t3\t9\n43243\t3\t8\n10814\t3\t4\n38634\t3\t1\n22460\t3\t4\n46838\t3\t6\n45053\t3\t6\n9624\t3\t4\n5493\t3\t8\n14373\t3\t0\n1951\t3\t0\n2931\t3\t8\n13443\t3\t1\n35245\t3\t5\n36027\t3\t0\n3351\t3\t4\n27317\t3\t9\n46594\t3\t6\n9111\t3\t2\n18638\t3\t6\n46841\t3\t2\n5329\t3\t5\n35163\t3\t6\n30305\t3\t1\n23314\t3\t1\n25922\t3\t9\n1658\t3\t5\n15876\t3\t6\n5592\t3\t1\n3365\t3\t8\n6198\t3\t8\n39871\t3\t6\n4302\t3\t8\n44980\t3\t9\n39398\t3\t4\n7200\t3\t1\n7122\t3\t5\n26009\t3\t5\n23326\t3\t0\n43744\t3\t5\n29449\t3\t0\n26624\t3\t9\n10784\t3\t8\n46571\t3\t5\n21921\t3\t7\n18283\t3\t6\n42650\t3\t2\n27831\t3\t6\n48326\t3\t1\n4221\t3\t7\n13204\t3\t9\n27152\t3\t6\n42189\t3\t4\n45038\t3\t9\n4449\t3\t8\n36273\t3\t6\n10101\t3\t6\n20447\t3\t6\n5799\t3\t9\n43733\t3\t1\n9052\t3\t9\n28891\t3\t7\n4994\t3\t0\n34714\t3\t0\n22484\t3\t1\n22245\t3\t0\n2353\t3\t5\n37117\t3\t0\n14751\t3\t8\n21578\t3\t0\n7224\t3\t0\n30779\t3\t6\n42028\t3\t2\n10427\t3\t0\n49906\t3\t5\n48346\t3\t2\n41747\t3\t4\n39972\t3\t0\n22577\t3\t5\n42801\t3\t1\n42223\t3\t9\n38100\t3\t2\n36422\t3\t9\n49632\t3\t5\n19245\t3\t9\n47518\t3\t1\n12601\t3\t0\n15217\t3\t2\n22273\t3\t6\n16751\t3\t2\n6493\t3\t0\n18442\t3\t2\n13313\t3\t5\n14234\t3\t5\n35595\t3\t5\n22278\t3\t5\n41020\t3\t9\n29936\t3\t7\n41021\t3\t2\n19913\t3\t2\n42187\t3\t1\n40847\t3\t1\n43411\t3\t8\n40954\t3\t7\n2809\t3\t9\n5478\t3\t9\n49408\t3\t1\n22193\t3\t5\n25686\t3\t5\n26462\t3\t4\n7460\t3\t4\n34185\t3\t7\n22143\t3\t5\n31440\t3\t8\n3546\t3\t8\n41989\t3\t7\n2770\t3\t9\n43832\t3\t7\n8592\t3\t8\n23443\t3\t8\n4083\t3\t2\n8947\t3\t5\n32312\t3\t1\n37998\t3\t2\n20593\t3\t2\n41853\t3\t1\n38445\t3\t0\n19229\t3\t7\n36852\t3\t1\n35428\t3\t2\n33582\t3\t1\n5914\t3\t0\n25683\t3\t5\n3910\t3\t9\n6199\t3\t6\n39789\t3\t7\n10209\t3\t2\n39428\t3\t7\n4146\t3\t8\n46862\t3\t8\n6980\t3\t1\n25136\t3\t1\n29273\t3\t6\n35715\t3\t5\n33168\t3\t1\n8104\t3\t7\n45151\t3\t0\n32555\t3\t1\n7230\t3\t5\n4519\t3\t5\n7765\t3\t9\n28792\t3\t6\n20194\t3\t1\n41213\t3\t1\n5713\t3\t4\n49773\t3\t6\n14543\t3\t7\n26472\t3\t1\n49574\t3\t4\n21366\t3\t8\n32936\t3\t4\n32517\t3\t6\n43257\t3\t6\n43722\t3\t9\n26862\t3\t6\n21049\t3\t9\n21015\t3\t0\n40869\t3\t4\n6205\t3\t1\n27108\t3\t9\n24193\t3\t7\n41892\t3\t9\n20784\t3\t7\n22135\t3\t9\n36264\t3\t5\n45275\t3\t2\n35704\t3\t2\n25378\t3\t1\n6071\t3\t9\n9968\t3\t7\n1160\t3\t4\n38684\t3\t7\n21832\t3\t2\n42321\t3\t9\n17828\t3\t5\n17841\t3\t6\n45947\t3\t5\n39681\t3\t1\n34236\t3\t2\n2412\t3\t4\n35557\t3\t8\n31194\t3\t6\n629\t3\t4\n19864\t3\t1\n46414\t3\t7\n15818\t3\t5\n995\t3\t9\n16946\t3\t5\n16604\t3\t2\n2359\t3\t7\n41168\t3\t5\n2947\t3\t7\n3084\t3\t7\n29322\t3\t8\n8356\t3\t8\n45251\t3\t9\n49240\t3\t6\n39355\t3\t5\n16438\t3\t1\n2723\t3\t9\n43438\t3\t9\n18329\t3\t0\n7909\t3\t5\n47198\t3\t9\n7768\t3\t9\n13907\t3\t9\n20117\t3\t0\n17440\t3\t2\n35071\t3\t6\n12050\t3\t5\n14064\t3\t6\n21818\t3\t2\n42134\t3\t2\n43968\t3\t4\n46160\t3\t1\n7719\t3\t5\n44139\t3\t6\n46976\t3\t7\n28142\t3\t1\n15175\t3\t1\n10310\t3\t4\n38377\t3\t6\n38006\t3\t4\n13064\t3\t8\n41937\t3\t8\n12966\t3\t6\n24100\t3\t4\n26657\t3\t8\n16619\t3\t2\n5475\t3\t2\n10182\t3\t9\n14578\t3\t1\n18188\t3\t9\n42999\t3\t6\n17919\t3\t0\n7075\t3\t6\n29607\t3\t8\n11617\t3\t1\n34987\t3\t9\n1710\t3\t2\n24727\t3\t9\n22512\t3\t4\n41229\t3\t7\n37095\t3\t0\n33612\t3\t4\n27652\t3\t1\n24896\t3\t6\n24906\t3\t1\n48132\t3\t7\n41053\t3\t8\n20255\t3\t4\n26716\t3\t6\n23986\t3\t1\n7426\t3\t0\n33345\t3\t1\n46805\t3\t9\n41874\t3\t5\n13201\t3\t1\n45191\t3\t0\n17672\t3\t4\n28437\t3\t4\n17930\t3\t8\n20159\t3\t1\n16284\t3\t5\n17926\t3\t1\n31535\t3\t8\n38338\t3\t6\n27826\t3\t7\n35427\t3\t2\n850\t3\t5\n42021\t3\t1\n42604\t3\t9\n36026\t3\t4\n47683\t3\t1\n28373\t3\t2\n49083\t3\t8\n22759\t3\t0\n24337\t3\t8\n19060\t3\t1\n11556\t3\t6\n40634\t3\t8\n12811\t3\t8\n17024\t3\t6\n10463\t3\t0\n3000\t3\t1\n38319\t3\t6\n41521\t3\t7\n43752\t3\t7\n29861\t3\t5\n12546\t3\t0\n33876\t3\t0\n3177\t3\t7\n12211\t3\t9\n32180\t3\t4\n10464\t3\t5\n16950\t3\t7\n26253\t3\t5\n34914\t3\t9\n24522\t3\t2\n28773\t3\t9\n24154\t3\t9\n15057\t3\t8\n11389\t3\t0\n4072\t3\t6\n18651\t3\t9\n43072\t3\t6\n2312\t3\t9\n49322\t3\t0\n11387\t3\t7\n12042\t3\t9\n16817\t3\t0\n19578\t3\t6\n27254\t3\t8\n45897\t3\t9\n23270\t3\t0\n33874\t3\t8\n47918\t3\t6\n922\t3\t4\n11419\t3\t0\n5896\t3\t4\n19514\t3\t2\n20529\t3\t7\n19068\t3\t9\n2057\t3\t4\n9995\t3\t2\n6783\t3\t9\n37204\t3\t8\n29523\t3\t0\n26690\t3\t5\n11596\t3\t0\n28772\t3\t6\n15953\t3\t6\n25773\t3\t2\n36077\t3\t7\n26261\t3\t9\n9305\t3\t5\n4915\t3\t0\n29154\t3\t0\n32160\t3\t2\n3843\t3\t0\n19025\t3\t5\n23702\t3\t6\n1002\t3\t2\n13222\t3\t5\n33601\t3\t0\n43464\t3\t0\n34407\t3\t4\n1845\t3\t2\n11623\t3\t9\n15640\t3\t7\n12837\t3\t6\n5242\t3\t6\n34170\t3\t4\n39773\t3\t4\n9613\t3\t5\n38093\t3\t1\n34042\t3\t4\n22662\t3\t1\n25676\t3\t5\n36779\t3\t6\n28697\t3\t8\n36240\t3\t5\n14820\t3\t0\n8246\t3\t2\n7213\t3\t2\n45901\t3\t9\n35375\t3\t4\n150\t3\t9\n1487\t3\t2\n5162\t3\t8\n6758\t3\t1\n4462\t3\t6\n36418\t3\t2\n22555\t3\t0\n25950\t3\t8\n6466\t3\t0\n34967\t3\t0\n17863\t3\t4\n28839\t3\t1\n26189\t3\t7\n22778\t3\t1\n1938\t3\t6\n35479\t3\t1\n46500\t3\t9\n31649\t3\t5\n9421\t3\t4\n36647\t3\t4\n9120\t3\t2\n12631\t3\t7\n24135\t3\t9\n15555\t3\t6\n9670\t3\t8\n23589\t3\t2\n40558\t3\t8\n2581\t3\t9\n19344\t3\t5\n37304\t3\t9\n17644\t3\t2\n33894\t3\t5\n36633\t3\t0\n17496\t3\t1\n35128\t3\t5\n39634\t3\t1\n3222\t3\t7\n21122\t3\t7\n39500\t3\t6\n30606\t3\t7\n17155\t3\t6\n19126\t3\t2\n550\t3\t9\n39071\t3\t2\n20431\t3\t2\n1461\t3\t9\n16547\t3\t0\n44124\t3\t4\n37514\t3\t8\n15228\t3\t6\n17041\t3\t5\n19234\t3\t9\n49822\t3\t7\n29324\t3\t5\n18798\t3\t5\n44585\t3\t7\n20337\t3\t9\n3956\t3\t5\n24611\t3\t7\n4139\t3\t8\n28880\t3\t5\n12450\t3\t8\n19895\t3\t9\n7804\t3\t4\n3728\t3\t6\n30708\t3\t9\n45754\t3\t9\n45931\t3\t8\n21640\t3\t9\n12681\t3\t1\n22794\t3\t6\n47394\t3\t8\n45282\t3\t4\n34889\t3\t8\n251\t3\t2\n1076\t3\t1\n12528\t3\t4\n6256\t3\t6\n26554\t3\t6\n43382\t3\t4\n49463\t3\t1\n37966\t3\t9\n33956\t3\t8\n47681\t3\t2\n11763\t3\t2\n17614\t3\t5\n49197\t3\t9\n29165\t3\t1\n29569\t3\t6\n28253\t3\t8\n42370\t3\t2\n22110\t3\t0\n42198\t3\t2\n34984\t3\t9\n15882\t3\t8\n33511\t3\t7\n19088\t3\t5\n5017\t3\t2\n37173\t3\t1\n33633\t3\t1\n10788\t3\t0\n48285\t3\t8\n7771\t3\t8\n14647\t3\t6\n11564\t3\t6\n5877\t3\t6\n18969\t3\t1\n34294\t3\t9\n21368\t3\t2\n44144\t3\t9\n17413\t3\t5\n40532\t3\t6\n23380\t3\t9\n949\t3\t6\n32510\t3\t1\n36894\t3\t7\n23974\t3\t5\n15793\t3\t2\n39151\t3\t6\n25103\t3\t4\n31754\t3\t2\n11458\t3\t8\n22244\t3\t6\n47684\t3\t7\n8943\t3\t6\n17505\t3\t9\n49840\t3\t9\n9908\t3\t4\n25215\t3\t1\n25986\t3\t2\n5106\t3\t9\n5192\t3\t1\n45192\t3\t8\n7049\t3\t5\n28669\t3\t1\n19080\t3\t7\n31934\t3\t5\n22425\t3\t1\n31344\t3\t2\n41581\t3\t2\n17214\t3\t4\n331\t3\t2\n8649\t3\t5\n8028\t3\t9\n19075\t3\t7\n38897\t3\t8\n19312\t3\t8\n45789\t3\t5\n37769\t3\t5\n45646\t3\t4\n24704\t3\t5\n49298\t3\t2\n5080\t3\t1\n8183\t3\t4\n12007\t3\t9\n32350\t3\t2\n8153\t3\t1\n34593\t3\t5\n20080\t3\t8\n49142\t3\t6\n25008\t3\t0\n14511\t3\t2\n15284\t3\t0\n11864\t3\t8\n10321\t3\t0\n24005\t3\t5\n10383\t3\t8\n6930\t3\t5\n7469\t3\t6\n34281\t3\t5\n33903\t3\t4\n38147\t3\t1\n12798\t3\t5\n6658\t3\t8\n7671\t3\t0\n32881\t3\t9\n846\t3\t6\n7539\t3\t2\n36219\t3\t7\n18858\t3\t1\n36980\t3\t2\n32358\t3\t7\n3218\t3\t7\n41349\t3\t8\n3801\t3\t1\n34437\t3\t2\n36870\t3\t2\n16432\t3\t8\n18497\t3\t0\n44819\t3\t2\n8349\t3\t9\n16449\t3\t1\n23461\t3\t7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## TEST","metadata":{}},{"cell_type":"code","source":"####TEST ONLY\ntest_labels = np.array(testset.targets)\n\nnum_to_change_test = int((percentage_to_change / 100) * np.sum(test_labels == target_class))\nindices_to_change_test = np.random.choice(np.where(test_labels == target_class)[0], num_to_change_test, replace=False)\n\nprint(\"Index\\tOriginal Label\\tNew Label\")\nfor index in indices_to_change_test:\n    new_label = np.random.choice(possible_new_labels)\n    print(f\"{index}\\t{test_labels[index]}\\t{new_label}\")\n    test_labels[index] = new_label\n\ntestset.targets = list(test_labels)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:07:59.715981Z","iopub.execute_input":"2024-03-03T11:07:59.716330Z","iopub.status.idle":"2024-03-03T11:07:59.748088Z","shell.execute_reply.started":"2024-03-03T11:07:59.716303Z","shell.execute_reply":"2024-03-03T11:07:59.747205Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Index\tOriginal Label\tNew Label\n7016\t3\t0\n5336\t3\t9\n4785\t3\t4\n8433\t3\t4\n5490\t3\t7\n2923\t3\t5\n6283\t3\t7\n8251\t3\t8\n2606\t3\t2\n2937\t3\t7\n4093\t3\t4\n9576\t3\t2\n3700\t3\t8\n882\t3\t2\n9992\t3\t7\n5313\t3\t9\n7717\t3\t8\n77\t3\t5\n558\t3\t1\n8337\t3\t0\n5655\t3\t2\n4495\t3\t4\n5779\t3\t2\n8141\t3\t6\n7291\t3\t8\n4407\t3\t2\n2422\t3\t5\n3013\t3\t0\n1346\t3\t5\n7349\t3\t1\n6009\t3\t0\n2646\t3\t6\n2878\t3\t8\n7489\t3\t7\n9562\t3\t6\n998\t3\t6\n6021\t3\t7\n3183\t3\t2\n2855\t3\t6\n4708\t3\t9\n3867\t3\t1\n5290\t3\t1\n9093\t3\t6\n8295\t3\t1\n5632\t3\t6\n3125\t3\t8\n8231\t3\t7\n7415\t3\t0\n9460\t3\t0\n251\t3\t9\n1275\t3\t2\n7004\t3\t8\n6680\t3\t4\n5424\t3\t8\n9647\t3\t5\n786\t3\t1\n4864\t3\t9\n8739\t3\t8\n5991\t3\t8\n4467\t3\t8\n6912\t3\t0\n7961\t3\t4\n1660\t3\t8\n608\t3\t1\n9043\t3\t6\n2049\t3\t0\n9089\t3\t9\n7569\t3\t2\n3280\t3\t4\n453\t3\t8\n6710\t3\t8\n3634\t3\t7\n3654\t3\t9\n3628\t3\t5\n2840\t3\t4\n586\t3\t5\n1377\t3\t2\n1088\t3\t4\n5671\t3\t8\n6026\t3\t2\n8196\t3\t0\n106\t3\t2\n9308\t3\t0\n2832\t3\t6\n5752\t3\t9\n6311\t3\t9\n945\t3\t6\n1373\t3\t0\n3594\t3\t2\n2173\t3\t9\n3249\t3\t2\n4637\t3\t6\n8996\t3\t6\n8548\t3\t5\n8077\t3\t9\n6990\t3\t0\n7212\t3\t9\n8665\t3\t7\n599\t3\t5\n7970\t3\t7\n1334\t3\t0\n8435\t3\t0\n5700\t3\t6\n5213\t3\t4\n2759\t3\t8\n3067\t3\t5\n5176\t3\t0\n5191\t3\t2\n4306\t3\t9\n6213\t3\t6\n4485\t3\t4\n9246\t3\t4\n650\t3\t6\n4210\t3\t1\n4043\t3\t2\n4147\t3\t6\n7384\t3\t4\n5029\t3\t5\n7275\t3\t6\n7207\t3\t8\n4106\t3\t9\n2253\t3\t2\n8099\t3\t2\n7228\t3\t8\n641\t3\t5\n1123\t3\t8\n1056\t3\t6\n9809\t3\t7\n597\t3\t4\n5084\t3\t5\n4032\t3\t0\n9740\t3\t1\n4818\t3\t6\n8491\t3\t4\n7105\t3\t6\n2831\t3\t9\n2181\t3\t1\n8467\t3\t0\n2489\t3\t9\n9967\t3\t9\n2963\t3\t8\n6786\t3\t4\n2972\t3\t5\n7962\t3\t8\n6174\t3\t6\n2900\t3\t7\n1605\t3\t2\n1883\t3\t9\n6163\t3\t9\n3884\t3\t4\n8490\t3\t7\n9316\t3\t7\n4876\t3\t0\n3391\t3\t2\n6865\t3\t2\n8662\t3\t1\n9453\t3\t6\n456\t3\t7\n2720\t3\t2\n6027\t3\t8\n6859\t3\t6\n9336\t3\t5\n9281\t3\t6\n2081\t3\t2\n5493\t3\t4\n6792\t3\t4\n7378\t3\t6\n2285\t3\t4\n7933\t3\t6\n1964\t3\t9\n646\t3\t1\n2268\t3\t5\n7509\t3\t2\n432\t3\t8\n6587\t3\t9\n5309\t3\t8\n8343\t3\t0\n3752\t3\t2\n4987\t3\t8\n9665\t3\t5\n1905\t3\t6\n8200\t3\t9\n7747\t3\t9\n7145\t3\t4\n515\t3\t8\n2306\t3\t5\n6825\t3\t4\n870\t3\t7\n3228\t3\t2\n6732\t3\t8\n1030\t3\t8\n7524\t3\t2\n1166\t3\t6\n5874\t3\t8\n831\t3\t4\n1947\t3\t9\n2952\t3\t4\n1179\t3\t5\n4765\t3\t2\n9404\t3\t9\n3835\t3\t1\n8580\t3\t6\n7014\t3\t5\n1395\t3\t4\n6134\t3\t6\n9228\t3\t7\n3180\t3\t4\n8620\t3\t8\n3387\t3\t9\n829\t3\t1\n5161\t3\t0\n3584\t3\t6\n2643\t3\t2\n9003\t3\t9\n2453\t3\t0\n4718\t3\t5\n4375\t3\t8\n4617\t3\t4\n4682\t3\t8\n2698\t3\t2\n5701\t3\t0\n7174\t3\t1\n9121\t3\t4\n2178\t3\t0\n2286\t3\t8\n7854\t3\t7\n9148\t3\t1\n187\t3\t7\n5605\t3\t5\n9218\t3\t1\n7915\t3\t5\n3073\t3\t9\n9812\t3\t1\n1595\t3\t1\n6345\t3\t5\n8169\t3\t6\n5630\t3\t9\n9748\t3\t2\n819\t3\t5\n7150\t3\t1\n6102\t3\t4\n6596\t3\t6\n5486\t3\t9\n8131\t3\t7\n5525\t3\t4\n3977\t3\t6\n5011\t3\t1\n9996\t3\t1\n8481\t3\t5\n9191\t3\t9\n7002\t3\t6\n4900\t3\t8\n1981\t3\t4\n224\t3\t0\n8362\t3\t0\n2350\t3\t0\n7211\t3\t0\n727\t3\t2\n8114\t3\t5\n1173\t3\t6\n4808\t3\t1\n9131\t3\t7\n9302\t3\t2\n4886\t3\t7\n1074\t3\t5\n2752\t3\t5\n8754\t3\t7\n9109\t3\t5\n302\t3\t8\n8680\t3\t4\n5268\t3\t8\n3736\t3\t9\n2871\t3\t9\n7374\t3\t8\n1454\t3\t8\n7224\t3\t2\n418\t3\t7\n9087\t3\t9\n2107\t3\t0\n8642\t3\t7\n3864\t3\t9\n4542\t3\t4\n4820\t3\t1\n5773\t3\t2\n7783\t3\t9\n6339\t3\t9\n7839\t3\t8\n676\t3\t1\n9022\t3\t4\n8023\t3\t1\n323\t3\t5\n2543\t3\t9\n9422\t3\t1\n8616\t3\t2\n5033\t3\t4\n8331\t3\t2\n7772\t3\t0\n5413\t3\t1\n1704\t3\t6\n205\t3\t0\n4845\t3\t4\n9839\t3\t4\n2175\t3\t2\n8966\t3\t8\n7853\t3\t7\n4804\t3\t2\n792\t3\t4\n1386\t3\t2\n8033\t3\t9\n2243\t3\t4\n8617\t3\t5\n7214\t3\t5\n1053\t3\t6\n6827\t3\t0\n2526\t3\t6\n2207\t3\t9\n5532\t3\t0\n671\t3\t7\n3901\t3\t8\n811\t3\t5\n2261\t3\t2\n5732\t3\t0\n2798\t3\t6\n9498\t3\t2\n6976\t3\t7\n3539\t3\t5\n2269\t3\t0\n1871\t3\t7\n3413\t3\t5\n7497\t3\t8\n103\t3\t9\n6893\t3\t7\n1280\t3\t2\n6237\t3\t5\n695\t3\t2\n5050\t3\t4\n356\t3\t9\n3143\t3\t9\n4155\t3\t0\n9295\t3\t2\n8174\t3\t4\n3900\t3\t2\n127\t3\t1\n2498\t3\t0\n9678\t3\t7\n3084\t3\t6\n7352\t3\t1\n367\t3\t0\n6062\t3\t6\n5381\t3\t6\n1269\t3\t2\n467\t3\t1\n2617\t3\t7\n7036\t3\t1\n3617\t3\t7\n866\t3\t1\n4393\t3\t0\n4674\t3\t0\n426\t3\t1\n6111\t3\t7\n1909\t3\t5\n6938\t3\t4\n1782\t3\t9\n9755\t3\t8\n573\t3\t5\n9226\t3\t7\n5228\t3\t2\n5198\t3\t5\n8338\t3\t4\n995\t3\t4\n1612\t3\t9\n6793\t3\t8\n7377\t3\t5\n5817\t3\t0\n6538\t3\t5\n4307\t3\t9\n7910\t3\t2\n9862\t3\t4\n688\t3\t7\n5206\t3\t4\n4458\t3\t6\n1180\t3\t5\n5733\t3\t9\n4457\t3\t2\n3810\t3\t8\n898\t3\t6\n5943\t3\t0\n1518\t3\t4\n3194\t3\t9\n6783\t3\t8\n7300\t3\t4\n5086\t3\t9\n2405\t3\t5\n4282\t3\t4\n2076\t3\t6\n7644\t3\t0\n2897\t3\t7\n1033\t3\t6\n6439\t3\t4\n0\t3\t2\n3130\t3\t2\n1468\t3\t2\n7813\t3\t5\n1848\t3\t7\n7709\t3\t7\n4962\t3\t7\n9994\t3\t4\n565\t3\t5\n9190\t3\t1\n1611\t3\t0\n4266\t3\t8\n4175\t3\t8\n4814\t3\t1\n4352\t3\t1\n4050\t3\t2\n862\t3\t1\n9433\t3\t9\n7807\t3\t4\n7714\t3\t6\n279\t3\t2\n1538\t3\t7\n9505\t3\t7\n5835\t3\t6\n4581\t3\t4\n3779\t3\t5\n690\t3\t5\n8181\t3\t2\n6842\t3\t9\n336\t3\t6\n6202\t3\t9\n9778\t3\t7\n7367\t3\t4\n7598\t3\t4\n2506\t3\t5\n6726\t3\t2\n6709\t3\t0\n2815\t3\t0\n5155\t3\t1\n7905\t3\t4\n7789\t3\t6\n8577\t3\t7\n3674\t3\t2\n9243\t3\t2\n115\t3\t6\n8484\t3\t4\n673\t3\t4\n3956\t3\t5\n6333\t3\t4\n5343\t3\t1\n6168\t3\t5\n4760\t3\t7\n8700\t3\t5\n7879\t3\t6\n874\t3\t8\n438\t3\t2\n2046\t3\t6\n4500\t3\t8\n8204\t3\t8\n3489\t3\t2\n9142\t3\t7\n916\t3\t9\n5506\t3\t8\n8930\t3\t6\n5908\t3\t5\n8401\t3\t0\n957\t3\t4\n7310\t3\t8\n6364\t3\t9\n6900\t3\t8\n3354\t3\t1\n1031\t3\t5\n7496\t3\t9\n8059\t3\t9\n5518\t3\t0\n3633\t3\t6\n397\t3\t0\n8326\t3\t2\n2632\t3\t7\n9338\t3\t7\n2822\t3\t1\n4574\t3\t4\n4422\t3\t2\n6647\t3\t5\n6744\t3\t0\n5410\t3\t8\n3353\t3\t7\n3231\t3\t2\n8299\t3\t6\n2612\t3\t6\n9141\t3\t8\n7026\t3\t7\n8203\t3\t7\n5925\t3\t5\n2660\t3\t4\n5560\t3\t7\n4071\t3\t7\n61\t3\t6\n1219\t3\t5\n1993\t3\t1\n3234\t3\t5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Accuracy after data poisoning","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nmodel.eval().to(device)\ncorrect_predictions = np.zeros(len(classes))\ntotal_samples = np.zeros(len(classes))\n\nwith torch.no_grad():\n    for (inputs, targets) in testloader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        outputs = model(inputs)\n        _, predicted = outputs.max(1)\n\n        for label, prediction in zip(targets, predicted):\n            if label == prediction:\n                correct_predictions[label] += 1\n            total_samples[label] += 1\n\nfor i, classname in enumerate(classes):\n    accuracy = 100 * correct_predictions[i] / total_samples[i]\n    print(f'Accuracy on test data {classname:5s} : {accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:07:59.749366Z","iopub.execute_input":"2024-03-03T11:07:59.749643Z","iopub.status.idle":"2024-03-03T11:08:18.715369Z","shell.execute_reply.started":"2024-03-03T11:07:59.749622Z","shell.execute_reply":"2024-03-03T11:08:18.714440Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Accuracy on test data plane : 0.19%\nAccuracy on test data car   : 0.00%\nAccuracy on test data bird  : 15.70%\nAccuracy on test data cat   : 75.80%\nAccuracy on test data deer  : 1.88%\nAccuracy on test data dog   : 2.17%\nAccuracy on test data frog  : 0.00%\nAccuracy on test data horse : 0.00%\nAccuracy on test data ship  : 0.00%\nAccuracy on test data truck : 1.61%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Implementing SimCLR","metadata":{}},{"cell_type":"markdown","source":"Loss function","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ndef nt_xent_loss(z1, z2, temperature=0.5):\n    z1_norm = F.normalize(z1, dim=1)\n    z2_norm = F.normalize(z2, dim=1)\n\n    sim_matrix = torch.einsum('ik,jk->ij', z1_norm, z2_norm)\n    neg_sim = -sim_matrix\n    log_prob = F.log_softmax(neg_sim / temperature, dim=1)\n    pos_label = torch.arange(z1.shape[0], device=z1.device).long().unsqueeze(1)\n    log_prob_pos = torch.gather(log_prob, 1, pos_label)\n\n    loss = -torch.mean(log_prob_pos)\n    return loss\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:08:18.716624Z","iopub.execute_input":"2024-03-03T11:08:18.716931Z","iopub.status.idle":"2024-03-03T11:08:18.723393Z","shell.execute_reply.started":"2024-03-03T11:08:18.716906Z","shell.execute_reply":"2024-03-03T11:08:18.722490Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Data Augmentations","metadata":{}},{"cell_type":"code","source":"\naugment_1 = transforms.Compose([\n    transforms.RandomResizedCrop(size=224),\n    transforms.RandomHorizontalFlip(p=0.5),\n])\n\naugment_2 = transforms.Compose([\n    transforms.RandomResizedCrop(size=224),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomGrayscale(p=0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:23:00.178508Z","iopub.execute_input":"2024-03-03T11:23:00.178895Z","iopub.status.idle":"2024-03-03T11:23:00.184672Z","shell.execute_reply.started":"2024-03-03T11:23:00.178863Z","shell.execute_reply":"2024-03-03T11:23:00.183832Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":" Model and Projection Head:","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, out_features):\n        super(ProjectionHead, self).__init__()\n        self.fc1 = nn.Linear(in_features, hidden_dim)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(hidden_dim, out_features)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:08:18.739152Z","iopub.execute_input":"2024-03-03T11:08:18.739439Z","iopub.status.idle":"2024-03-03T11:08:18.747816Z","shell.execute_reply.started":"2024-03-03T11:08:18.739417Z","shell.execute_reply":"2024-03-03T11:08:18.747085Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b4', pretrained=False)\nmodel.eval().to(device)\nmodel = torch.load(\"/kaggle/input/ef-net/ef_net_78.pth\")\n\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\naccuracy = checkpoint['accuracy']\naverage_loss_test = checkpoint['test_accuracy']\naverage_loss = checkpoint['test_loss']\nlearning_rate = checkpoint['learning_rate']\n# model.classifier = nn.Identity()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:24:32.856541Z","iopub.execute_input":"2024-03-03T11:24:32.857028Z","iopub.status.idle":"2024-03-03T11:24:33.666619Z","shell.execute_reply.started":"2024-03-03T11:24:32.856998Z","shell.execute_reply":"2024-03-03T11:24:33.665659Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## SimCLR training","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-03T11:14:35.966837Z","iopub.execute_input":"2024-03-03T11:14:35.967592Z","iopub.status.idle":"2024-03-03T11:14:36.267051Z","shell.execute_reply.started":"2024-03-03T11:14:35.967563Z","shell.execute_reply":"2024-03-03T11:14:36.265739Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images)):\n\u001b[1;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m images[i]  \u001b[38;5;66;03m# Access individual image from the batch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43maugment_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Apply augmentation to the image\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     images[i] \u001b[38;5;241m=\u001b[39m img \n\u001b[1;32m     12\u001b[0m img1 \u001b[38;5;241m=\u001b[39m augment_1(img1)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:979\u001b[0m, in \u001b[0;36mRandomResizedCrop.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    972\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be cropped and resized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Randomly cropped and resized image.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m     i, j, h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mresized_crop(img, i, j, h, w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation, antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:940\u001b[0m, in \u001b[0;36mRandomResizedCrop.get_params\u001b[0;34m(img, scale, ratio)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_params\u001b[39m(img: Tensor, scale: List[\u001b[38;5;28mfloat\u001b[39m], ratio: List[\u001b[38;5;28mfloat\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    929\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get parameters for ``crop`` for a random sized crop.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m        sized crop.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 940\u001b[0m     _, height, width \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m     area \u001b[38;5;241m=\u001b[39m height \u001b[38;5;241m*\u001b[39m width\n\u001b[1;32m    943\u001b[0m     log_ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mtensor(ratio))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:76\u001b[0m, in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     74\u001b[0m     _log_api_usage_once(get_dimensions)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mget_dimensions(img)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:19\u001b[0m, in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dimensions\u001b[39m(img: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43m_assert_image_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     21\u001b[0m     height, width \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:15\u001b[0m, in \u001b[0;36m_assert_image_tensor\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_image_tensor\u001b[39m(img: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_tensor_a_torch_image(img):\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor is not a torch image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Tensor is not a torch image."],"ename":"TypeError","evalue":"Tensor is not a torch image.","output_type":"error"}]},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torchvision.transforms import ToPILImage, ToTensor\nfrom torchvision.transforms.functional import to_tensor, to_pil_image\nimport torch.nn.functional as F\nmodel.to(device)\n\ndef nt_xent_loss(z1, z2, temperature=0.3):\n    z1_norm = F.normalize(z1, dim=1)\n    z2_norm = F.normalize(z2, dim=1)\n\n    sim_matrix = torch.einsum('ik,jk->ij', z1_norm, z2_norm)\n    neg_sim = -sim_matrix\n    log_prob = F.log_softmax(neg_sim / temperature, dim=1)\n    pos_label = torch.arange(z1.shape[0], device=z1.device).long().unsqueeze(1)\n    log_prob_pos = torch.gather(log_prob, 1, pos_label)\n\n    loss = -torch.mean(log_prob_pos)\n    return loss\n    \n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, out_features):\n        super(ProjectionHead, self).__init__()\n        self.fc1 = nn.Linear(in_features, hidden_dim)\n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n        self.relu = nn.ReLU(inplace=True)\n        # Example: Adding an additional layer\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.bn2 = nn.BatchNorm1d(hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, out_features)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.fc3(x)\n        return x\n\n    \n\nto_pil_image = transforms.ToPILImage()\n    \naugment_1 = transforms.Compose([\n    transforms.RandomResizedCrop(size=128),\n    transforms.RandomHorizontalFlip(p=0.5),\n])\n\naugment_2 = transforms.Compose([\n    transforms.RandomResizedCrop(size=128),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomGrayscale(p=0.2),\n])\nlearning_rate=0.001\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n\nprojection_head = ProjectionHead(1000, 128, 128).to(device)\n# train(epochs=100, trainloader=trainloader, optimizer=optimizer, scheduler=scheduler)\n\n\nfrom tqdm import tqdm\nepochs = 50\nnum_epochs = epochs\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n    total_batches = 0\n    correct_pairs = 0\n\n    train_loader = tqdm(trainloader, total=len(trainloader), desc=f'Epoch [{epoch + 1}/{num_epochs}]')\n\n    for _, (images, _) in enumerate(train_loader):\n        images = images.to(device)\n        augmented_images = []\n        for image in images:\n            image_pil = to_pil_image(image.cpu())\n            img1 = augment_1(image_pil)\n            img2 = augment_2(image_pil)\n            img1 = to_tensor(img1).to(device)\n            img2 = to_tensor(img2).to(device)\n            augmented_images.extend([img1, img2])\n\n        augmented_images = torch.stack(augmented_images, dim=0)\n\n        h1, h2 = model(augmented_images[::2]), model(augmented_images[1::2])\n        z1 = projection_head(h1)\n        z2 = projection_head(h2)\n\n        loss = nt_xent_loss(z1, z2, temperature=0.3)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Compute similarity for positive pairs and compare against negatives for a rough \"accuracy\"\n        sim_pos = F.cosine_similarity(z1, z2)\n        sim_neg_mean = (torch.sum(torch.exp(-loss)) - torch.sum(torch.exp(sim_pos))) / (len(sim_pos) * (len(sim_pos) - 1))\n        correct_pairs += torch.sum(sim_pos > sim_neg_mean).item()\n\n        total_loss += loss.item()\n        total_batches += 1\n\n        current_average_loss = total_loss / total_batches\n        current_accuracy = correct_pairs / (total_batches * images.size(0))\n        train_loader.set_postfix(loss=current_average_loss, accuracy=current_accuracy)\n\n    average_loss = total_loss / total_batches\n\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:51:13.705610Z","iopub.execute_input":"2024-03-03T16:51:13.706352Z","iopub.status.idle":"2024-03-03T16:51:21.560834Z","shell.execute_reply.started":"2024-03-03T16:51:13.706321Z","shell.execute_reply":"2024-03-03T16:51:21.559606Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":77,"outputs":[{"name":"stderr","text":"Epoch [1/50]:   1%|         | 10/782 [00:07<09:55,  1.30it/s, accuracy=0.991, loss=4.26]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[77], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m loss \u001b[38;5;241m=\u001b[39m nt_xent_loss(z1, z2, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 95\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Compute similarity for positive pairs and compare against negatives for a rough \"accuracy\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\n\nmodel.eval().to(device)\ncorrect_predictions = np.zeros(len(classes))\ntotal_samples = np.zeros(len(classes))\n\nwith torch.no_grad():\n    for (inputs, targets) in testloader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        outputs = model(inputs)\n        _, predicted = outputs.max(1)\n\n        for label, prediction in zip(targets, predicted):\n            if label == prediction:\n                correct_predictions[label] += 1\n            total_samples[label] += 1\n\nfor i, classname in enumerate(classes):\n    accuracy = 100 * correct_predictions[i] / total_samples[i]\n    print(f'Accuracy on test data {classname:5s} : {accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:00:06.243013Z","iopub.execute_input":"2024-03-03T17:00:06.243953Z","iopub.status.idle":"2024-03-03T17:00:12.492686Z","shell.execute_reply.started":"2024-03-03T17:00:06.243915Z","shell.execute_reply":"2024-03-03T17:00:12.491742Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Accuracy on test data plane : 0.20%\nAccuracy on test data car   : 99.40%\nAccuracy on test data bird  : 0.10%\nAccuracy on test data cat   : 0.90%\nAccuracy on test data deer  : 1.70%\nAccuracy on test data dog   : 16.00%\nAccuracy on test data frog  : 0.00%\nAccuracy on test data horse : 0.00%\nAccuracy on test data ship  : 0.70%\nAccuracy on test data truck : 0.00%\n","output_type":"stream"}]}]}